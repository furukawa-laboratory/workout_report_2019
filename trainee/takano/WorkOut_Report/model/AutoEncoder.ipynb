{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# オートエンコーダーとは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### オートエンコーダーは与えられた画像群を自動的に圧縮及び復元を行うものである。オートエンコーダーが行う圧縮は非可逆圧縮であるため、復元された画像は多少粗くなっている。オートエンコーダーの実用的な用途は,データのノイズ除去とデータの視覚化に応用できる次元削減がある。視覚化においてはt-SNEの方が性能が良いらしい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# オートエンコーダーを作る(MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.3527 - val_loss: 0.2712\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2637 - val_loss: 0.2523\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.2409 - val_loss: 0.2280\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2206 - val_loss: 0.2115 loss: 0.22\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2069 - val_loss: 0.1999\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1965 - val_loss: 0.1905\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1879 - val_loss: 0.1826\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1807 - val_loss: 0.1761\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1744 - val_loss: 0.1702\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1688 - val_loss: 0.1649\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1637 - val_loss: 0.1602\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1591 - val_loss: 0.1558\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1549 - val_loss: 0.1515\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1510 - val_loss: 0.1480\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1475 - val_loss: 0.1446\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1443 - val_loss: 0.1415\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1414 - val_loss: 0.1388\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1388 - val_loss: 0.1365\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1363 - val_loss: 0.1338\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1340 - val_loss: 0.1316\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1318 - val_loss: 0.1294\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1297 - val_loss: 0.1274\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.1277 - val_loss: 0.1255\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1258 - val_loss: 0.1236\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1240 - val_loss: 0.1218\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1223 - val_loss: 0.1202\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1207 - val_loss: 0.1185\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1192 - val_loss: 0.1170\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1177 - val_loss: 0.1155\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1163 - val_loss: 0.1142\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1151 - val_loss: 0.1130\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1139 - val_loss: 0.1118\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1127 - val_loss: 0.1107\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1117 - val_loss: 0.1097\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1107 - val_loss: 0.1087\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1098 - val_loss: 0.1078\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1090 - val_loss: 0.1071\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1082 - val_loss: 0.1063\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1074 - val_loss: 0.1055\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1067 - val_loss: 0.1049\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1061 - val_loss: 0.1043\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1055 - val_loss: 0.1037\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1049 - val_loss: 0.1031\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1044 - val_loss: 0.1026\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1039 - val_loss: 0.1021\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1034 - val_loss: 0.1017- ETA: 0s - los\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1030 - val_loss: 0.1013\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1026 - val_loss: 0.1009\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1022 - val_loss: 0.1005\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1018 - val_loss: 0.1001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "encoding_dim = 32 #エンコードする次元を決めている\n",
    "input_img = Input(shape=(784,))# MNISTは32*32=784次元なのでそれに合わせる\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "encoder = Model(input_img, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adadelta',loss='binary_crossentropy')\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _),(x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32')/ 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "autoencoder.fit(x_train,x_train,\n",
    "               epochs=50,\n",
    "               batch_size=256,\n",
    "               shuffle=True,\n",
    "               validation_data=(x_test,x_test))\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20,4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2,n,i+1)\n",
    "    plt.imshow(x_test[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "plt.show()\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(encoding_dim,activation='relu',activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = Dense(784,activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input_img, decoded)\n",
    "n = 10\n",
    "plt.figure(figsize=(20,4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2,n,i+1)\n",
    "    plt.imshow(x_test[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "plt.show()\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.3600 - val_loss: 0.26460s - \n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.2589 - val_loss: 0.2530\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2434 - val_loss: 0.2330\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2271 - val_loss: 0.2227\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2172 - val_loss: 0.2082\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.2008 - val_loss: 0.1947\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1907 - val_loss: 0.1864\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1827 - val_loss: 0.1775\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1762 - val_loss: 0.1721\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1709 - val_loss: 0.1670\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1651 - val_loss: 0.1627\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1600 - val_loss: 0.1561\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1559 - val_loss: 0.1551\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1529 - val_loss: 0.1510\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1506 - val_loss: 0.1483\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1481 - val_loss: 0.1462\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1459 - val_loss: 0.1452: 0.14 - ETA: 0s - \n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1439 - val_loss: 0.1422\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1418 - val_loss: 0.1407\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1400 - val_loss: 0.1382\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1386 - val_loss: 0.1358\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1369 - val_loss: 0.1345\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1356 - val_loss: 0.1353\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1343 - val_loss: 0.1331\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1330 - val_loss: 0.1306\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1316 - val_loss: 0.1287\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1304 - val_loss: 0.1309\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1292 - val_loss: 0.1267\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1281 - val_loss: 0.1253\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1267 - val_loss: 0.1248\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.1257 - val_loss: 0.1236\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1246 - val_loss: 0.1222 ETA: 2s - loss: 0.1 - E\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.1237 - val_loss: 0.1230\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1228 - val_loss: 0.1198\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1219 - val_loss: 0.1199\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1211 - val_loss: 0.1196\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1203 - val_loss: 0.1176\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1196 - val_loss: 0.1169\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1189 - val_loss: 0.1184\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1182 - val_loss: 0.1178\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1176 - val_loss: 0.1171\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1171 - val_loss: 0.1174\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1164 - val_loss: 0.1131\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1158 - val_loss: 0.1140\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1152 - val_loss: 0.1140\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1147 - val_loss: 0.1152\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1142 - val_loss: 0.1118\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1136 - val_loss: 0.1128\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1130 - val_loss: 0.1113\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1127 - val_loss: 0.1104\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1122 - val_loss: 0.1120\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1118 - val_loss: 0.1099\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1114 - val_loss: 0.1117\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1110 - val_loss: 0.1089\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1107 - val_loss: 0.1128\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1102 - val_loss: 0.1103\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1100 - val_loss: 0.1090\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1096 - val_loss: 0.1083\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1092 - val_loss: 0.1079\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1089 - val_loss: 0.1081\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1087 - val_loss: 0.1064\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1083 - val_loss: 0.1063\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1081 - val_loss: 0.1071\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1077 - val_loss: 0.1064\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1075 - val_loss: 0.1043\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1071 - val_loss: 0.1089\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1068 - val_loss: 0.1060\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1067 - val_loss: 0.1075\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1063 - val_loss: 0.1062\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1060 - val_loss: 0.1044\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1057 - val_loss: 0.1037\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1056 - val_loss: 0.1039\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1052 - val_loss: 0.1041\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1050 - val_loss: 0.1039\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1048 - val_loss: 0.1042\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1046 - val_loss: 0.1019\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1042 - val_loss: 0.1029\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1041 - val_loss: 0.1027\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1039 - val_loss: 0.1006\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1036 - val_loss: 0.1021\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1035 - val_loss: 0.1025\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1033 - val_loss: 0.1026\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1031 - val_loss: 0.1015\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1028 - val_loss: 0.1028\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1025 - val_loss: 0.1037\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1025 - val_loss: 0.1012\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1022 - val_loss: 0.1014\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1022 - val_loss: 0.1020\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1019 - val_loss: 0.0999\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1017 - val_loss: 0.1008\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1016 - val_loss: 0.1018\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1015 - val_loss: 0.1015\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.1013 - val_loss: 0.0997\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1011 - val_loss: 0.1000\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.1009 - val_loss: 0.1024\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1008 - val_loss: 0.1003\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.1006 - val_loss: 0.0985\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1004 - val_loss: 0.0990\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.1002 - val_loss: 0.0989\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1002 - val_loss: 0.0995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b8177c668>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64,activation='relu')(encoded)\n",
    "encoded = Dense(32,activation='relu')(encoded)\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "autoencoder = Model(input_img,decoded)\n",
    "autoencoder.compile(optimizer='adadelta',loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train,x_train,epochs=100,batch_size=256,shuffle=True,validation_data=(x_test,x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.2138 - val_loss: 0.1668\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1528 - val_loss: 0.1437\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1394 - val_loss: 0.1289\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1318 - val_loss: 0.1294\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1267 - val_loss: 0.1227\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1232 - val_loss: 0.1225\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1201 - val_loss: 0.1154\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1180 - val_loss: 0.1183\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1163 - val_loss: 0.1131\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1150 - val_loss: 0.1112\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1134 - val_loss: 0.1113\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1123 - val_loss: 0.1085\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1110 - val_loss: 0.1107\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1102 - val_loss: 0.1143\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1094 - val_loss: 0.1083\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1087 - val_loss: 0.1099\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1078 - val_loss: 0.1055\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1074 - val_loss: 0.1061\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1069 - val_loss: 0.1043\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1061 - val_loss: 0.1039\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1056 - val_loss: 0.1041\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1051 - val_loss: 0.1041\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1049 - val_loss: 0.1044\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1044 - val_loss: 0.1029\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1038 - val_loss: 0.1064\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1035 - val_loss: 0.0998\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1032 - val_loss: 0.1017\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1029 - val_loss: 0.1049\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1026 - val_loss: 0.1055\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1025 - val_loss: 0.1002\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1019 - val_loss: 0.0987\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1015 - val_loss: 0.0998\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1015 - val_loss: 0.1020\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1013 - val_loss: 0.0996\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1009 - val_loss: 0.1000\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1006 - val_loss: 0.1000\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1005 - val_loss: 0.1008\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1004 - val_loss: 0.0962\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.0998 - val_loss: 0.0986\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0998 - val_loss: 0.0999\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0998 - val_loss: 0.0993\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0996 - val_loss: 0.0994\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.0993 - val_loss: 0.0961\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0991 - val_loss: 0.0980\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0989 - val_loss: 0.0990\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0986 - val_loss: 0.0959\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0987 - val_loss: 0.0994\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0983 - val_loss: 0.0959\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0984 - val_loss: 0.0981\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.0981 - val_loss: 0.0973\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num must be 1 <= num <= 20, not 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2f3259d22c97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msubplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m     \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[0mbyebye\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1365\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_axstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     raise ValueError(\n\u001b[0;32m     59\u001b[0m                         (\"num must be 1 <= num <= {maxn}, not {num}\"\n\u001b[1;32m---> 60\u001b[1;33m                         ).format(maxn=rows*cols, num=num))\n\u001b[0m\u001b[0;32m     61\u001b[0m                 self._subplotspec = GridSpec(\n\u001b[0;32m     62\u001b[0m                         rows, cols, figure=self.figure)[int(num) - 1]\n",
      "\u001b[1;31mValueError\u001b[0m: num must be 1 <= num <= 20, not 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Input,Dense,Conv2D,MaxPooling2D,UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(28,28,1))\n",
    "\n",
    "x = Conv2D(16,(3,3), activation='relu',padding='same')(input_img)\n",
    "x = MaxPooling2D((2,2),padding='same')(x)\n",
    "x = Conv2D(8,(3,3),activation='relu',padding='same')(x)\n",
    "x = MaxPooling2D((2,2),padding='same')(x)\n",
    "x = Conv2D(8,(3,3),activation='relu',padding='same')(x)\n",
    "encoded = MaxPooling2D((2,2),padding='same')(x)\n",
    "\n",
    "x = Conv2D(8,(3,3), activation='relu',padding='same')(encoded)\n",
    "x = UpSampling2D((2,2))(x)\n",
    "x = Conv2D(8,(3,3),activation='relu',padding='same')(x)\n",
    "x = UpSampling2D((2,2))(x)\n",
    "x = Conv2D(16,(3,3),activation='relu')(x)\n",
    "x = UpSampling2D((2,2))(x)\n",
    "decoded =Conv2D(1,(3,3),activation='sigmoid',padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img,decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n",
    "decoded_imgs = autoencoder.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 32 into shape (4,32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ac811b24da0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_imgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 32 into shape (4,32)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20,4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2,n,i+1)\n",
    "    plt.imshow(x_test[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20,8))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i+1)\n",
    "    plt.imshow(encoded_imgs[i].reshape(4,4*8).T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application to image denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "(x_train, _), (x_test,_) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "noise_factor = 0.5\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0,scale=1.0,size=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0,scale=1.0,size=x_test.shape)\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy,0.,1.)\n",
    "x_test_noisy = np.clip(x_test_noisy,0.,1.)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i+1)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 出力にノイズが混ざっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.1845 - val_loss: 0.1281\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.1212 - val_loss: 0.1155\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.1126 - val_loss: 0.1081\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.1084 - val_loss: 0.1058\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.1059 - val_loss: 0.1061\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.1043 - val_loss: 0.1025\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.1032 - val_loss: 0.1033\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.1021 - val_loss: 0.1009\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.1014 - val_loss: 0.0994\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.1010 - val_loss: 0.0991\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.1007 - val_loss: 0.0993\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.1002 - val_loss: 0.0999\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0999 - val_loss: 0.0996\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0994 - val_loss: 0.0985\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0992 - val_loss: 0.0976\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0989 - val_loss: 0.0979\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0988 - val_loss: 0.0985\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0986 - val_loss: 0.0981\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0984 - val_loss: 0.0970\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0981 - val_loss: 0.0987\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0980 - val_loss: 0.0967\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0978 - val_loss: 0.0966\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0977 - val_loss: 0.0965\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0975 - val_loss: 0.0964\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0974 - val_loss: 0.0963\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0973 - val_loss: 0.0966\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0973 - val_loss: 0.0975\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0970 - val_loss: 0.0974\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0969 - val_loss: 0.0959\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0968 - val_loss: 0.0957\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0967 - val_loss: 0.0961\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0967 - val_loss: 0.0973\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0965 - val_loss: 0.0959\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0965 - val_loss: 0.0960\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0964 - val_loss: 0.0960\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0963 - val_loss: 0.0972\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0963 - val_loss: 0.0952\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0962 - val_loss: 0.0952\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0961 - val_loss: 0.0958\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0961 - val_loss: 0.0952\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0960 - val_loss: 0.0954\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0959 - val_loss: 0.0959\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0959 - val_loss: 0.0961\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0958 - val_loss: 0.0953\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0957 - val_loss: 0.0955\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0957 - val_loss: 0.0951\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0956 - val_loss: 0.0947\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0955 - val_loss: 0.0947\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0956 - val_loss: 0.0949\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0955 - val_loss: 0.0954\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0954 - val_loss: 0.0947\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0954 - val_loss: 0.0947\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0954 - val_loss: 0.0946\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0953 - val_loss: 0.0947\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0953 - val_loss: 0.0947\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0952 - val_loss: 0.0945\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0952 - val_loss: 0.0945\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0952 - val_loss: 0.0948\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0952 - val_loss: 0.0947\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0951 - val_loss: 0.0952\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0951 - val_loss: 0.0945\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0950 - val_loss: 0.0944\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 136s 2ms/step - loss: 0.0950 - val_loss: 0.0957\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 133s 2ms/step - loss: 0.0949 - val_loss: 0.0944\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0950 - val_loss: 0.0953\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0950 - val_loss: 0.0943\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0949 - val_loss: 0.0946\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0948 - val_loss: 0.0943\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0948 - val_loss: 0.0944\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 135s 2ms/step - loss: 0.0948 - val_loss: 0.0944\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 134s 2ms/step - loss: 0.0948 - val_loss: 0.0953\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0947 - val_loss: 0.0948\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0948 - val_loss: 0.0951\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0947 - val_loss: 0.0941\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0947 - val_loss: 0.0942\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0946 - val_loss: 0.0949\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0946 - val_loss: 0.0948\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0947 - val_loss: 0.0946\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0946 - val_loss: 0.0945\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 139s 2ms/step - loss: 0.0945 - val_loss: 0.0952\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0945 - val_loss: 0.0946\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 138s 2ms/step - loss: 0.0945 - val_loss: 0.0941\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 139s 2ms/step - loss: 0.0945 - val_loss: 0.0941\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 138s 2ms/step - loss: 0.0945 - val_loss: 0.0939\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0944 - val_loss: 0.0942\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0944 - val_loss: 0.0945\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 129s 2ms/step - loss: 0.0945 - val_loss: 0.0950\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0944 - val_loss: 0.0947\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 129s 2ms/step - loss: 0.0944 - val_loss: 0.0950\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0944 - val_loss: 0.0939\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0943 - val_loss: 0.0940\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 129s 2ms/step - loss: 0.0943 - val_loss: 0.0939\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0943 - val_loss: 0.0938\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0943 - val_loss: 0.0946\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 139s 2ms/step - loss: 0.0943 - val_loss: 0.0942\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0943 - val_loss: 0.0942\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0942 - val_loss: 0.0942\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0942 - val_loss: 0.0938\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0942 - val_loss: 0.0940\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 137s 2ms/step - loss: 0.0942 - val_loss: 0.0943\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-88ce187ae6ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_noisy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mz_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (7, 7, 32)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                histogram_freq=0, write_graph=False)])\n",
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., std=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# end-to-end autoencoder\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))\n",
    "\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timesteps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-85f7d3e6bc04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'timesteps' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(timesteps, input_dim))\n",
    "encoded = LSTM(latent_dim)(inputs)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded = LSTM(input_dim, return_sequences=True)(decoded)\n",
    "\n",
    "sequence_autoencoder = Model(inputs, decoded)\n",
    "encoder = Model(inputs, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b1cc2e7a0c38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mz_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,Conv2D,MaxPooling2D,UpSampling2D\n",
    "from keras import backend as K\n",
    "\n",
    "x = Input(batch_shape=(batch_size, original_dim))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., std=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# end-to-end autoencoder\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = objectives.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))\n",
    "\n",
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fashion mnistにオートエンコーダー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 55s 2us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 1s 0us/step\n",
      "(60000, 784)\n",
      "(10000, 784)\n",
      "WARNING:tensorflow:From c:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.5287 - val_loss: 0.4572\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.4272 - val_loss: 0.4080\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3979 - val_loss: 0.3910\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3819 - val_loss: 0.3761\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3680 - val_loss: 0.3638\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.3564 - val_loss: 0.3532\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.3468 - val_loss: 0.3446\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.3392 - val_loss: 0.3379\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.3332 - val_loss: 0.3326\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.3284 - val_loss: 0.3283\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.3245 - val_loss: 0.3248\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.3213 - val_loss: 0.3219\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.3187 - val_loss: 0.3196\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.3165 - val_loss: 0.3175\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.3146 - val_loss: 0.3158\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.3130 - val_loss: 0.3143\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3117 - val_loss: 0.3131\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3105 - val_loss: 0.3121\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.3095 - val_loss: 0.3112\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.3086 - val_loss: 0.3103\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3078 - val_loss: 0.3095\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3071 - val_loss: 0.3088\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3064 - val_loss: 0.3081\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.3058 - val_loss: 0.3075\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3052 - val_loss: 0.3070\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3046 - val_loss: 0.3064\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3041 - val_loss: 0.3059\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.3035 - val_loss: 0.3054\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3031 - val_loss: 0.3049\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3026 - val_loss: 0.3045\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3021 - val_loss: 0.3041\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3017 - val_loss: 0.3036\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3013 - val_loss: 0.3032\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3009 - val_loss: 0.3028\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3005 - val_loss: 0.3024\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.3002 - val_loss: 0.3021\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.2998 - val_loss: 0.3017\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2995 - val_loss: 0.3014\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2991 - val_loss: 0.3011\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2988 - val_loss: 0.3007\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2985 - val_loss: 0.3004\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.2982 - val_loss: 0.3001\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.2979 - val_loss: 0.2998\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2976 - val_loss: 0.2995\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2973 - val_loss: 0.2994\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2970 - val_loss: 0.2990\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.2967 - val_loss: 0.2987\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.2964 - val_loss: 0.2984\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2962 - val_loss: 0.2981\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2959 - val_loss: 0.2979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adadelta',loss='binary_crossentropy')\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _),(x_test, _) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32')/ 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "autoencoder.fit(x_train,x_train,\n",
    "               epochs=50,\n",
    "               batch_size=256,\n",
    "               shuffle=True,\n",
    "               validation_data=(x_test,x_test))\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20,4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2,n,i+1)\n",
    "    plt.imshow(x_test[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "from keras import regularizers\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(encoding_dim,activation='relu',activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = Dense(784,activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20,4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2,n,i+1)\n",
    "    plt.imshow(x_test[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# エンコーダーデコーダー共に1層の簡単な構成ではあるが、それなりに復元できている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10に対してオートエンコーダーを構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adadelta',loss='binary_crossentropy')\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _),(x_test, _) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32')/ 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "autoencoder.fit(x_train,x_train,\n",
    "               epochs=50,\n",
    "               batch_size=256,\n",
    "               shuffle=True,\n",
    "               validation_data=(x_test,x_test))\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "import matplotlib.pyplot as plt\n",
    "n = 10\n",
    "plt.figure(figsize=(20,4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2,n,i+1)\n",
    "    plt.imshow(x_test[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "from keras import regularizers\n",
    "encoding_dim = 32\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(encoding_dim,activation='relu',activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "decoded = Dense(784,activation='sigmoid')(encoded)\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

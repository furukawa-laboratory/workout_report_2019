# Support Vector Machine: SVM について
## はじめに
SVMはパターン認識手法の一つであり，カーネルトリックと呼ばれる手法を用いて，非線形の識別関数を構築します．非線形の識別関数を構築できるということは，もちろん線形の識別関数を構築することも可能です．

一般に識別器において，訓練データに含まれていない未学習データに対しても高い識別性能を発揮するには，何かしらの工夫を施すことによって汎化性能を向上させる必要があります．SVMでは，この汎化性能の向上を「マージン最大化」によって実現しています．

SVMは基本的に2つのクラスを識別する識別器ですが，複数のSVMを組み合わせることで多クラスの識別器を構築することも可能です．難しいため，本稿では触れません．

## 問題設定
SVMを適用できる条件を以下に示します．


$$ D = \{(\boldsymbol{x}_1,y_1),...,(\boldsymbol{x}_n,y_n)\} $$

$m$は特徴量の個数であり，多変量データにおける説明変数の数です．

$$ \boldsymbol{x}^T_i = (x_1,...,x_m)$$

認識したい対象のクラスの総数を$K$とし，各クラスを$C_1,...,C_K$と表します．

## SVMのタスク
パターン認識におけるタスクは，未知の認識対象を計測して得られてた特徴量からその対象がどのクラスに属するかを判定する識別器を構成することです．

そのためには，すでにクラスが分かっている訓練データ特量ベクトルとクラスとの対応関係を学習する必要があります．

未知の認識対象の識別には，学習した対応関係をもとに対象が属するであろうクラスを決定します．この際，識別を誤る確率をできる限り小さくすることが望ましい．

## SVM

![](https://i.imgur.com/UWpOTPT.png =300x300)

SVMは単純な線形しきい素子を用いて，2クラスのパターン識別器を構成する手法です．
訓練データ集合から，「マージン最大化」を使って線形しきい素子のパラメータ$(\boldsymbol{w},h)$を学習します．

線形しきい素子は，上の図に示したようなニューロンモデルであり，入力特徴ベクトル$\boldsymbol{x}^T_i = (x_1,...,x_m)$に対し，識別関数
$$ y = \mbox{sign}(\boldsymbol{w}^T\boldsymbol{x}-h) $$
によって2値の出力値を計算する．$\boldsymbol{w}$は各入力に対する重みにあたるパラメータであり，$h$はしきい値です．式(1)は，入力特徴ベクトルと重みベクトルの総和がしきい値を越えたときのみ1を出力する．

※線形しきい素子：出力として0,1の2値をとるようなモデルを，入力の線形和$( \sum_{i}^{N}w_ix_i)$がしきい値$(h)$を越えた時のみ1を出力することから，「線形しきい素子」という．
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目次(Table of Contents)\n",
    "### 1. バイアスとバリアンスについて説明せよ\n",
    "### 2. Cross Validationについて説明せよ\n",
    "### 3. sklearnのBoston house-pricesデータセットをloadして線形回帰を用いて学習せよ[(参考)](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html)\n",
    "### 4. 学習させた結果をsklearnのCross Validationで評価せよ[(参考)](https://tech.mof-mof.co.jp/blog/scikit-learn-cross-validation.html)\n",
    "### ~~5. 学習結果の平均・分散を計算せよ[(参考)](http://tekenuko.hatenablog.com/entry/2016/09/19/151547)~~ 保留"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. バイアスとバリアンスについて\n",
    "https://nigimitama.hatenablog.jp/entry/2018/11/24/062732\n",
    "\n",
    "MSE(Mean Square Error)の式からVarianceとBiasの式を導出する<br>\n",
    "$$\n",
    "\\begin{align}\n",
    "MSE(\\hat\\theta,\\theta)&\n",
    "=E[(\\hat\\theta-\\theta)^{2}] \\\\\n",
    "                      &=E[(\\hat\\theta-E[\\hat\\theta]+E[\\hat\\theta]-\\theta)^{2}]\\\\\n",
    "                      &=E[(\\hat\\theta-E[\\hat\\theta])]^{2}+[E[\\hat\\theta]-\\theta]^{2}\\\\\n",
    "                      &=Var(\\hat\\theta)+Bias(\\hat\\theta,\\theta)\n",
    "\\end{align}\n",
    "$$\n",
    "- バイアス(bias)とは、学習アルゴリズムの間違った仮定による誤差である。高いバイアスは、特徴量とターゲットの出力間の関連性を見逃す可能性がある(underfitting)\n",
    "- バリアンス(variance)とは、トレーニングセットにおける小さなゆらぎ（変動）に対する感度から生じる誤差である。高いバリアンスは、アルゴリズムが意図した出力でなく、トレーニングデータのランダムノイズをモデル化する可能性がある(overfitting)<br>\n",
    "[Bias–variance tradeoffのwikipedia](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)を参考<br>\n",
    "\n",
    "これならわかる深層学習（入門）を参考\n",
    "- underfitting…データの豊かさに対してモデルの自由度が小さすぎると、データの構造をとらえることが全くできない。つまり訓練誤差の値が大きすぎて、何の予測能力も得られないこと。未学習(under learning)とも呼ばれる\n",
    "- overfitting…モデルの自由度が大きすぎると、学習データのもつノイズ（統計的なゆらぎ）までも正確にフィッティングしてしまい、与えれた訓練データに関する訓練誤差の値はどんどん小さくなる。しかし、訓練データに適合することで未知のデータに対してどんどん予測能力を失っていく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cross Validation(交差検証)について\n",
    "[交差検証のWikipedia](https://ja.wikipedia.org/wiki/%E4%BA%A4%E5%B7%AE%E6%A4%9C%E8%A8%BC)を参考\n",
    "- 交差検証とは、統計学において標本データを分割し、その一部をまず解析して、残る部分でその解析のテストを行い、解析自身の妥当性の検証・確認に充てる手法を指す。データの解析がどれだけ本当に母集団に対処できるかを良い近似で検証・確認するための手法である。つまり、交差検証によってデータの分割によらない頑強な汎化精度の評価が可能になる。また、データセットを学習データとテストデータに分けた場合、テストデータを使わずに汎化性能が高いかどうか調べることができるのも特徴である。\n",
    "- 交差検証の主な種類<br>\n",
    "・ホールドアウト検証・・・初期標本群から事例を無作為に選択しテスト事例を形成し、残る事例を訓練事例とする。ただし、データを交差させないため、交差検証には分類されない<br>\n",
    "・K-分割交差検証(K-fold cross-validation)・・・標本群をK個に分割し、そのうちの1つをテスト事例とし、残るK-1個を訓練事例とするのが一般的である。交差検証は、K個に分割された標本群それぞれをテスト事例としてk回検証を行う。そして、k個の精度の平均値をモデルの評価値とする<br>\n",
    "・leave-one-out 交差検証(LOOCV，1個抜き検証)・・・標本群から1つの事例だけを抜き出してテスト事例とし、残りを訓練事例とする。これを全事例が1回ずつテスト事例となるよう検証を繰り返す。これはK-分割交差検証のKを標本サイズにした場合と同じである。ただし、LOCCVにはカーネル回帰やティホノフ正則化などと関連がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. sklearnのBoston house-pricesデータセットをloadして線形回帰を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (404, 13), X_test.shape: (102, 13)\n",
      "y_train.shape: (404,), y_test.shape: (102,)\n",
      "Coefficients: \n",
      " [-1.19443447e-01  4.47799511e-02  5.48526168e-03  2.34080361e+00\n",
      " -1.61236043e+01  3.70870901e+00 -3.12108178e-03 -1.38639737e+00\n",
      "  2.44178327e-01 -1.09896366e-02 -1.04592119e+00  8.11010693e-03\n",
      " -4.92792725e-01]\n",
      "Mean squared error: 33.45\n",
      "Variance score(R^2 score): 0.59\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    boston.data, boston.target,\n",
    "                                    test_size=0.2, random_state=0)\n",
    "print('X_train.shape: {}, X_test.shape: {}'.format(X_train.shape, X_test.shape))\n",
    "print('y_train.shape: {}, y_test.shape: {}'.format(y_train.shape, y_test.shape))\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "print('Variance score(R^2 score): %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/cross_validation.html#the-cross-validate-function-and-multiple-metric-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. 学習させた結果をsklearnのCross Validationで評価せよ\n",
    "[sklearnのmodelの評価方法(scoring)](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)<br>\n",
    "[jupyter notebookの数式表記方法](https://qiita.com/namoshika/items/63db972bfd1030f8264a)<br>\n",
    "[CrossValidation + GridSearchCV](https://qiita.com/tomov3/items/039d4271ed30490edf7b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (303, 13) (203, 13)\n",
      "scores: [0.593 0.744 0.552 0.794 0.775]\n",
      "Accuracy: 0.69 (+/- 0.20)\n"
     ]
    }
   ],
   "source": [
    "# 最新のsklearnではcross_validationが存在しない？？？\n",
    "#from sklearn import cross_validation\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "\n",
    "# ボストンの家の部屋数と、家の価格データ（詳しくは公式参照）\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "# sklearn.model_selection.train_test_splitを使うと簡単にトレーニングデータとテストデータを分割出来る\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    boston.data, boston.target, test_size=0.4, random_state=0) # random_stateはrandom seedのこと、指定しなかったらrandomな変数になる\n",
    "print(boston.data.shape, X_train.shape, X_test.shape)\n",
    "\n",
    "# 学習\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# regr.score: 決定係数を出力。予測値xと正解値yの相関を測る\n",
    "# あるパラメータにおけるcv回の平均スコア（R^2)\n",
    "# ただし、線形回帰はパラメータがないためCross Validationで最適なパラメータを探す必要がないためあまり意味はない？\n",
    "scores = cross_val_score(regr, X_train, y_train, cv=5, scoring='r2')\n",
    "print('scores: {}'.format(scores))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数値的にモデルの性能を評価する指標の例に、平均二乗誤差(Mean Squared Error: MSE)や決定係数($R^2$)がある<br>\n",
    "$MSE=\\frac{1}{n}\\sum_{i=1}^{n}(y^{(i)}-y^{(i)}_{pred})^2$<br>\n",
    "$R^{2}=1-\\frac{MSE}{Var(y)}$<br>\n",
    "$R^{2}$スコアは負～1.0の値を取るので、0.69はそこそこできていると感じた"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~~5. 学習結果の平均・分散を計算せよ~~\n",
    "[Plotting Validation Curves](https://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html#sphx-glr-auto-examples-model-selection-plot-validation-curve-py)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regr: [-1.037e-01  5.586e-02  5.882e-02  2.505e+00 -1.903e+01  3.254e+00\n",
      " -3.222e-03 -1.576e+00  2.587e-01 -1.147e-02 -1.108e+00  5.501e-03\n",
      " -5.596e-01]\n",
      "pred_mean: 22.096720823737087, pred_var: 60.40325264082388\n",
      "true_mean: 22.213793103448275, true_var: 82.73054866655343\n"
     ]
    }
   ],
   "source": [
    "regr.fit(X_train, y_train)\n",
    "pred = regr.predict(X_test)\n",
    "print('regr: {}'.format(regr.coef_))\n",
    "print('pred_mean: {}, pred_var: {}'.format(np.mean(pred), np.var(pred)))\n",
    "print('true_mean: {}, true_var: {}'.format(np.mean(y_test), np.var(y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
